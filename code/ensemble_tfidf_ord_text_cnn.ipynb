{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ml_python/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from common_helper import *\n",
    "from nltk_helper import *\n",
    "from keras_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dr = \"../input/train.json\"\n",
    "test_dr = \"../input/test.json\"\n",
    "traindf, testdf = data_load(train_dr, test_dr)\n",
    "x_train, y_train = word_data_preprocessing(traindf)\n",
    "x_test, _ = word_data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=lambda d: d.split(',')).fit(x_train)\n",
    "x_train = tfidf.fit_transform(x_train).toarray()\n",
    "x_test = tfidf.transform(x_test).toarray()\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(traindf.cuisine.values)\n",
    "y_train = lb.transform(traindf.cuisine.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/strawberry/code/keras_helper.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(560, input_shape=(6696,), activation=\"selu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(560, init='glorot_uniform', activation='selu', input_shape=(x_train.shape[1],)))\n",
      "/root/strawberry/code/keras_helper.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(140, kernel_initializer=\"glorot_uniform\", activation=\"selu\")`\n",
      "  model.add(Dense(140, init='glorot_uniform', activation='selu'))\n",
      "/root/anaconda3/envs/ml_python/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/18\n",
      "35796/35796 [==============================] - 3s 97us/step - loss: 2.6135 - acc: 0.3195 - val_loss: 2.1506 - val_acc: 0.3813\n",
      "Epoch 2/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 1.9108 - acc: 0.4751 - val_loss: 1.5915 - val_acc: 0.5820\n",
      "Epoch 3/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 1.4201 - acc: 0.6307 - val_loss: 1.2300 - val_acc: 0.6637\n",
      "Epoch 4/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 1.1083 - acc: 0.7058 - val_loss: 1.0067 - val_acc: 0.7205\n",
      "Epoch 5/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.9115 - acc: 0.7513 - val_loss: 0.8723 - val_acc: 0.7494\n",
      "Epoch 6/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.7778 - acc: 0.7877 - val_loss: 0.7934 - val_acc: 0.7705\n",
      "Epoch 7/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.6874 - acc: 0.8093 - val_loss: 0.7442 - val_acc: 0.7810\n",
      "Epoch 8/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.6193 - acc: 0.8262 - val_loss: 0.7172 - val_acc: 0.7873\n",
      "Epoch 9/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.5657 - acc: 0.8397 - val_loss: 0.7023 - val_acc: 0.7891\n",
      "Epoch 10/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.5218 - acc: 0.8524 - val_loss: 0.6958 - val_acc: 0.7936\n",
      "Epoch 11/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.4926 - acc: 0.8578 - val_loss: 0.6936 - val_acc: 0.7926\n",
      "Epoch 12/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4631 - acc: 0.8649 - val_loss: 0.6927 - val_acc: 0.7954\n",
      "Epoch 13/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 0.4336 - acc: 0.8760 - val_loss: 0.6984 - val_acc: 0.7954\n",
      "Epoch 14/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.4147 - acc: 0.8788 - val_loss: 0.7013 - val_acc: 0.7939\n",
      "Epoch 15/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.3958 - acc: 0.8845 - val_loss: 0.7076 - val_acc: 0.7931\n",
      "Epoch 16/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.3791 - acc: 0.8894 - val_loss: 0.7153 - val_acc: 0.7893\n",
      "Epoch 17/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.3673 - acc: 0.8908 - val_loss: 0.7224 - val_acc: 0.7908\n",
      "Epoch 18/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.3549 - acc: 0.8938 - val_loss: 0.7303 - val_acc: 0.7896\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/18\n",
      "35796/35796 [==============================] - 3s 70us/step - loss: 2.6301 - acc: 0.3417 - val_loss: 2.1588 - val_acc: 0.4279\n",
      "Epoch 2/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 1.8998 - acc: 0.5033 - val_loss: 1.5710 - val_acc: 0.5835\n",
      "Epoch 3/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 1.3976 - acc: 0.6333 - val_loss: 1.2059 - val_acc: 0.6724\n",
      "Epoch 4/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 1.0967 - acc: 0.7033 - val_loss: 0.9975 - val_acc: 0.7157\n",
      "Epoch 5/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.9107 - acc: 0.7532 - val_loss: 0.8717 - val_acc: 0.7564\n",
      "Epoch 6/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.7829 - acc: 0.7855 - val_loss: 0.7973 - val_acc: 0.7735\n",
      "Epoch 7/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.6872 - acc: 0.8102 - val_loss: 0.7490 - val_acc: 0.7826\n",
      "Epoch 8/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 0.6185 - acc: 0.8261 - val_loss: 0.7193 - val_acc: 0.7883\n",
      "Epoch 9/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.5667 - acc: 0.8400 - val_loss: 0.7016 - val_acc: 0.7898\n",
      "Epoch 10/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.5244 - acc: 0.8504 - val_loss: 0.6940 - val_acc: 0.7926\n",
      "Epoch 11/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4876 - acc: 0.8611 - val_loss: 0.6921 - val_acc: 0.7929\n",
      "Epoch 12/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4592 - acc: 0.8680 - val_loss: 0.6920 - val_acc: 0.7936\n",
      "Epoch 13/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4371 - acc: 0.8742 - val_loss: 0.6963 - val_acc: 0.7946\n",
      "Epoch 14/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4170 - acc: 0.8794 - val_loss: 0.7023 - val_acc: 0.7949\n",
      "Epoch 15/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4016 - acc: 0.8817 - val_loss: 0.7065 - val_acc: 0.7929\n",
      "Epoch 16/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 0.3836 - acc: 0.8878 - val_loss: 0.7140 - val_acc: 0.7924\n",
      "Epoch 17/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.3648 - acc: 0.8925 - val_loss: 0.7221 - val_acc: 0.7926\n",
      "Epoch 18/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.3543 - acc: 0.8955 - val_loss: 0.7286 - val_acc: 0.7901\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/18\n",
      "35796/35796 [==============================] - 3s 71us/step - loss: 2.6413 - acc: 0.3458 - val_loss: 2.1522 - val_acc: 0.4321\n",
      "Epoch 2/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 1.8968 - acc: 0.4959 - val_loss: 1.5731 - val_acc: 0.5782\n",
      "Epoch 3/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 1.3974 - acc: 0.6265 - val_loss: 1.2091 - val_acc: 0.6674\n",
      "Epoch 4/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 1.0982 - acc: 0.7038 - val_loss: 0.9951 - val_acc: 0.7134\n",
      "Epoch 5/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.9046 - acc: 0.7535 - val_loss: 0.8687 - val_acc: 0.7486\n",
      "Epoch 6/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.7798 - acc: 0.7845 - val_loss: 0.7936 - val_acc: 0.7695\n",
      "Epoch 7/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 0.6870 - acc: 0.8081 - val_loss: 0.7459 - val_acc: 0.7856\n",
      "Epoch 8/18\n",
      "35796/35796 [==============================] - 2s 66us/step - loss: 0.6204 - acc: 0.8239 - val_loss: 0.7176 - val_acc: 0.7931\n",
      "Epoch 9/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.5673 - acc: 0.8401 - val_loss: 0.7025 - val_acc: 0.7969\n",
      "Epoch 10/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.5253 - acc: 0.8491 - val_loss: 0.6923 - val_acc: 0.7999\n",
      "Epoch 11/18\n",
      "35796/35796 [==============================] - 2s 61us/step - loss: 0.4950 - acc: 0.8576 - val_loss: 0.6885 - val_acc: 0.7976\n",
      "Epoch 12/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.4644 - acc: 0.8666 - val_loss: 0.6888 - val_acc: 0.7974\n",
      "Epoch 13/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.4398 - acc: 0.8739 - val_loss: 0.6903 - val_acc: 0.7976\n",
      "Epoch 14/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.4176 - acc: 0.8792 - val_loss: 0.6973 - val_acc: 0.7944\n",
      "Epoch 15/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4037 - acc: 0.8804 - val_loss: 0.7028 - val_acc: 0.7944\n",
      "Epoch 16/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.3866 - acc: 0.8871 - val_loss: 0.7100 - val_acc: 0.7946\n",
      "Epoch 17/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.3683 - acc: 0.8914 - val_loss: 0.7187 - val_acc: 0.7916\n",
      "Epoch 18/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.3597 - acc: 0.8948 - val_loss: 0.7294 - val_acc: 0.7901\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/18\n",
      "35796/35796 [==============================] - 3s 73us/step - loss: 2.6440 - acc: 0.3009 - val_loss: 2.2009 - val_acc: 0.3758\n",
      "Epoch 2/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 1.9490 - acc: 0.4706 - val_loss: 1.6270 - val_acc: 0.5809\n",
      "Epoch 3/18\n",
      "35796/35796 [==============================] - 2s 61us/step - loss: 1.4457 - acc: 0.6274 - val_loss: 1.2519 - val_acc: 0.6604\n",
      "Epoch 4/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 1.1276 - acc: 0.6978 - val_loss: 1.0202 - val_acc: 0.7139\n",
      "Epoch 5/18\n",
      "35796/35796 [==============================] - 2s 61us/step - loss: 0.9227 - acc: 0.7528 - val_loss: 0.8757 - val_acc: 0.7526\n",
      "Epoch 6/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.7848 - acc: 0.7850 - val_loss: 0.7933 - val_acc: 0.7738\n",
      "Epoch 7/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.6890 - acc: 0.8102 - val_loss: 0.7462 - val_acc: 0.7818\n",
      "Epoch 8/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.6166 - acc: 0.8257 - val_loss: 0.7169 - val_acc: 0.7911\n",
      "Epoch 9/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.5634 - acc: 0.8406 - val_loss: 0.7006 - val_acc: 0.7956\n",
      "Epoch 10/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.5240 - acc: 0.8521 - val_loss: 0.6909 - val_acc: 0.7986\n",
      "Epoch 11/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.4906 - acc: 0.8597 - val_loss: 0.6891 - val_acc: 0.7986\n",
      "Epoch 12/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.4601 - acc: 0.8671 - val_loss: 0.6884 - val_acc: 0.8002\n",
      "Epoch 13/18\n",
      "35796/35796 [==============================] - 2s 61us/step - loss: 0.4359 - acc: 0.8745 - val_loss: 0.6928 - val_acc: 0.7981\n",
      "Epoch 14/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.4153 - acc: 0.8797 - val_loss: 0.6975 - val_acc: 0.7974\n",
      "Epoch 15/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.3999 - acc: 0.8827 - val_loss: 0.7043 - val_acc: 0.7956\n",
      "Epoch 16/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.3804 - acc: 0.8888 - val_loss: 0.7125 - val_acc: 0.7934\n",
      "Epoch 17/18\n",
      "35796/35796 [==============================] - 2s 61us/step - loss: 0.3670 - acc: 0.8906 - val_loss: 0.7186 - val_acc: 0.7911\n",
      "Epoch 18/18\n",
      "35796/35796 [==============================] - 2s 60us/step - loss: 0.3547 - acc: 0.8945 - val_loss: 0.7287 - val_acc: 0.7908\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/18\n",
      "35796/35796 [==============================] - 3s 75us/step - loss: 2.6427 - acc: 0.3502 - val_loss: 2.1495 - val_acc: 0.4251\n",
      "Epoch 2/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 1.8907 - acc: 0.4930 - val_loss: 1.5714 - val_acc: 0.5835\n",
      "Epoch 3/18\n",
      "35796/35796 [==============================] - 2s 66us/step - loss: 1.4042 - acc: 0.6300 - val_loss: 1.2180 - val_acc: 0.6672\n",
      "Epoch 4/18\n",
      "35796/35796 [==============================] - 2s 66us/step - loss: 1.1059 - acc: 0.7061 - val_loss: 1.0051 - val_acc: 0.7152\n",
      "Epoch 5/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.9147 - acc: 0.7524 - val_loss: 0.8738 - val_acc: 0.7499\n",
      "Epoch 6/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.7854 - acc: 0.7870 - val_loss: 0.7963 - val_acc: 0.7675\n",
      "Epoch 7/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.6887 - acc: 0.8106 - val_loss: 0.7504 - val_acc: 0.7795\n",
      "Epoch 8/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.6183 - acc: 0.8271 - val_loss: 0.7194 - val_acc: 0.7906\n",
      "Epoch 9/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.5645 - acc: 0.8400 - val_loss: 0.7037 - val_acc: 0.7936\n",
      "Epoch 10/18\n",
      "35796/35796 [==============================] - 2s 63us/step - loss: 0.5220 - acc: 0.8525 - val_loss: 0.6947 - val_acc: 0.7946\n",
      "Epoch 11/18\n",
      "35796/35796 [==============================] - 2s 65us/step - loss: 0.4871 - acc: 0.8594 - val_loss: 0.6912 - val_acc: 0.7961\n",
      "Epoch 12/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4598 - acc: 0.8683 - val_loss: 0.6941 - val_acc: 0.7961\n",
      "Epoch 13/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4373 - acc: 0.8732 - val_loss: 0.6961 - val_acc: 0.7976\n",
      "Epoch 14/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.4132 - acc: 0.8802 - val_loss: 0.7003 - val_acc: 0.7974\n",
      "Epoch 15/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 0.3957 - acc: 0.8824 - val_loss: 0.7061 - val_acc: 0.7956\n",
      "Epoch 16/18\n",
      "35796/35796 [==============================] - 2s 62us/step - loss: 0.3776 - acc: 0.8907 - val_loss: 0.7134 - val_acc: 0.7939\n",
      "Epoch 17/18\n",
      "35796/35796 [==============================] - 2s 64us/step - loss: 0.3666 - acc: 0.8910 - val_loss: 0.7221 - val_acc: 0.7921\n",
      "Epoch 18/18\n",
      "35796/35796 [==============================] - 2s 61us/step - loss: 0.3530 - acc: 0.8940 - val_loss: 0.7326 - val_acc: 0.7914\n"
     ]
    }
   ],
   "source": [
    "last = []\n",
    "for i in range(5):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        mdl = load_model(x_train)\n",
    "        mdl.fit(x_train, y_train, nb_epoch=18, batch_size=4000,validation_split=0.1)\n",
    "        y_test = mdl.predict(x_test)     \n",
    "        last.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dr = \"../input/train.json\"\n",
    "# test_dr = \"../input/test.json\"\n",
    "# traindf, testdf = data_load(train_dr, test_dr)\n",
    "# x_train, y_train = data_preprocessing(traindf)\n",
    "# x_test, _ = data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(analyzer=lambda d: d.split(','),ngram_range=(1,2)).fit(x_train)\n",
    "# x_train = tfidf.fit_transform(x_train).toarray()\n",
    "# x_test = tfidf.transform(x_test).toarray()\n",
    "\n",
    "# lb = preprocessing.LabelBinarizer()\n",
    "# lb.fit(traindf.cuisine.values)\n",
    "# y_train = lb.transform(traindf.cuisine.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     with K.tf.device('/gpu:0'):\n",
    "#         mdl = load_model(x_train)\n",
    "#         mdl.fit(x_train, y_train, nb_epoch=13, batch_size=4000,validation_split=0.1)\n",
    "#         #train_predict = mdl.predict(x_train)\n",
    "#         y_test = mdl.predict(x_test)     \n",
    "#         #tf_idf_predictions = lb.inverse_transform(y_test)\n",
    "#         a.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from original_helper import *\n",
    "from common_helper import *\n",
    "from ord_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dr = \"../input/train.json\"\n",
    "test_dr = \"../input/test.json\"\n",
    "traindf, testdf = data_load(train_dr, test_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data_preprocessing(traindf)\n",
    "x_test, _ = data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_vectorizer(x_train)\n",
    "x_test = data_vectorizer(x_test)\n",
    "\n",
    "x_train = [np.array(i) for i in x_train]\n",
    "x_test = [np.array(i) for i in x_test]\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(traindf.cuisine.values)\n",
    "y_train = lb.transform(traindf.cuisine.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/strawberry/code/keras_helper.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(560, kernel_initializer=\"glorot_uniform\", input_shape=(2000,), activation=\"selu\")`\n",
      "  model.add(Dense(560, init='glorot_uniform', activation='selu', input_shape=(x_train.shape[1],)))\n",
      "/root/strawberry/code/keras_helper.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(140, kernel_initializer=\"glorot_uniform\", activation=\"selu\")`\n",
      "  model.add(Dense(140, init='glorot_uniform', activation='selu'))\n",
      "/root/anaconda3/envs/ml_python/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/20\n",
      "35796/35796 [==============================] - 1s 32us/step - loss: 4.4084 - acc: 0.1706 - val_loss: 2.0374 - val_acc: 0.4585\n",
      "Epoch 2/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 2.7680 - acc: 0.3345 - val_loss: 1.7452 - val_acc: 0.5334\n",
      "Epoch 3/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 2.1125 - acc: 0.4683 - val_loss: 1.4609 - val_acc: 0.5897\n",
      "Epoch 4/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.7991 - acc: 0.5181 - val_loss: 1.3124 - val_acc: 0.6217\n",
      "Epoch 5/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.6130 - acc: 0.5539 - val_loss: 1.2116 - val_acc: 0.6445\n",
      "Epoch 6/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.4943 - acc: 0.5836 - val_loss: 1.1594 - val_acc: 0.6631\n",
      "Epoch 7/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.4016 - acc: 0.6027 - val_loss: 1.1179 - val_acc: 0.6742\n",
      "Epoch 8/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.3337 - acc: 0.6159 - val_loss: 1.1000 - val_acc: 0.6780\n",
      "Epoch 9/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.2873 - acc: 0.6273 - val_loss: 1.0825 - val_acc: 0.6840\n",
      "Epoch 10/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.2367 - acc: 0.6398 - val_loss: 1.0563 - val_acc: 0.6880\n",
      "Epoch 11/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.2048 - acc: 0.6492 - val_loss: 1.0500 - val_acc: 0.6921\n",
      "Epoch 12/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.1859 - acc: 0.6531 - val_loss: 1.0378 - val_acc: 0.6938\n",
      "Epoch 13/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.1427 - acc: 0.6639 - val_loss: 1.0271 - val_acc: 0.6973\n",
      "Epoch 14/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.1307 - acc: 0.6664 - val_loss: 1.0330 - val_acc: 0.6976\n",
      "Epoch 15/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.1049 - acc: 0.6738 - val_loss: 1.0211 - val_acc: 0.7029\n",
      "Epoch 16/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.0789 - acc: 0.6787 - val_loss: 1.0198 - val_acc: 0.7024\n",
      "Epoch 17/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.0607 - acc: 0.6840 - val_loss: 1.0089 - val_acc: 0.7044\n",
      "Epoch 18/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.0371 - acc: 0.6908 - val_loss: 1.0126 - val_acc: 0.7059\n",
      "Epoch 19/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.0287 - acc: 0.6924 - val_loss: 1.0143 - val_acc: 0.7056\n",
      "Epoch 20/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.0185 - acc: 0.6969 - val_loss: 1.0106 - val_acc: 0.7056\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/20\n",
      "35796/35796 [==============================] - 1s 25us/step - loss: 4.4392 - acc: 0.1635 - val_loss: 2.0580 - val_acc: 0.4412\n",
      "Epoch 2/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 2.8483 - acc: 0.3213 - val_loss: 1.7375 - val_acc: 0.5266\n",
      "Epoch 3/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 2.1796 - acc: 0.4529 - val_loss: 1.4729 - val_acc: 0.5865\n",
      "Epoch 4/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.8232 - acc: 0.5123 - val_loss: 1.2957 - val_acc: 0.6247\n",
      "Epoch 5/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.6257 - acc: 0.5505 - val_loss: 1.2168 - val_acc: 0.6438\n",
      "Epoch 6/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.4981 - acc: 0.5806 - val_loss: 1.1603 - val_acc: 0.6599\n",
      "Epoch 7/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.4120 - acc: 0.5967 - val_loss: 1.1187 - val_acc: 0.6724\n",
      "Epoch 8/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.3412 - acc: 0.6159 - val_loss: 1.0943 - val_acc: 0.6777\n",
      "Epoch 9/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.2980 - acc: 0.6239 - val_loss: 1.0717 - val_acc: 0.6903\n",
      "Epoch 10/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.2434 - acc: 0.6366 - val_loss: 1.0631 - val_acc: 0.6913\n",
      "Epoch 11/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.2187 - acc: 0.6443 - val_loss: 1.0473 - val_acc: 0.6958\n",
      "Epoch 12/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.1859 - acc: 0.6529 - val_loss: 1.0486 - val_acc: 0.6956\n",
      "Epoch 13/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.1551 - acc: 0.6565 - val_loss: 1.0303 - val_acc: 0.6951\n",
      "Epoch 14/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.1328 - acc: 0.6654 - val_loss: 1.0309 - val_acc: 0.6993\n",
      "Epoch 15/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.1135 - acc: 0.6708 - val_loss: 1.0205 - val_acc: 0.6948\n",
      "Epoch 16/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.0945 - acc: 0.6756 - val_loss: 1.0241 - val_acc: 0.6991\n",
      "Epoch 17/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.0640 - acc: 0.6819 - val_loss: 1.0135 - val_acc: 0.7016\n",
      "Epoch 18/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.0525 - acc: 0.6871 - val_loss: 1.0244 - val_acc: 0.7026\n",
      "Epoch 19/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.0309 - acc: 0.6914 - val_loss: 1.0051 - val_acc: 0.7036\n",
      "Epoch 20/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.0146 - acc: 0.6961 - val_loss: 1.0082 - val_acc: 0.7061\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/20\n",
      "35796/35796 [==============================] - 1s 26us/step - loss: 4.4228 - acc: 0.1667 - val_loss: 2.1612 - val_acc: 0.3994\n",
      "Epoch 2/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 2.7174 - acc: 0.3406 - val_loss: 1.6575 - val_acc: 0.5440\n",
      "Epoch 3/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 2.0800 - acc: 0.4710 - val_loss: 1.4199 - val_acc: 0.5953\n",
      "Epoch 4/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.7687 - acc: 0.5245 - val_loss: 1.2984 - val_acc: 0.6295\n",
      "Epoch 5/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.6038 - acc: 0.5606 - val_loss: 1.2012 - val_acc: 0.6579\n",
      "Epoch 6/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.4817 - acc: 0.5835 - val_loss: 1.1538 - val_acc: 0.6644\n",
      "Epoch 7/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.3958 - acc: 0.5993 - val_loss: 1.1138 - val_acc: 0.6767\n",
      "Epoch 8/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.3373 - acc: 0.6169 - val_loss: 1.0937 - val_acc: 0.6820\n",
      "Epoch 9/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.2865 - acc: 0.6273 - val_loss: 1.0806 - val_acc: 0.6815\n",
      "Epoch 10/20\n",
      "35796/35796 [==============================] - 1s 18us/step - loss: 1.2459 - acc: 0.6366 - val_loss: 1.0611 - val_acc: 0.6893\n",
      "Epoch 11/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.1972 - acc: 0.6502 - val_loss: 1.0433 - val_acc: 0.6973\n",
      "Epoch 12/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.1711 - acc: 0.6558 - val_loss: 1.0387 - val_acc: 0.6951\n",
      "Epoch 13/20\n",
      "35796/35796 [==============================] - 1s 17us/step - loss: 1.1401 - acc: 0.6665 - val_loss: 1.0321 - val_acc: 0.6983\n",
      "Epoch 14/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.1214 - acc: 0.6661 - val_loss: 1.0260 - val_acc: 0.6998\n",
      "Epoch 15/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.0922 - acc: 0.6759 - val_loss: 1.0109 - val_acc: 0.7036\n",
      "Epoch 16/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.0788 - acc: 0.6798 - val_loss: 1.0221 - val_acc: 0.7034\n",
      "Epoch 17/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.0574 - acc: 0.6837 - val_loss: 1.0045 - val_acc: 0.7054\n",
      "Epoch 18/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.0525 - acc: 0.6862 - val_loss: 1.0311 - val_acc: 0.7001\n",
      "Epoch 19/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.0278 - acc: 0.6928 - val_loss: 1.0084 - val_acc: 0.7039\n",
      "Epoch 20/20\n",
      "35796/35796 [==============================] - 1s 16us/step - loss: 1.0162 - acc: 0.6966 - val_loss: 1.0132 - val_acc: 0.7069\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        mdl = load_model(x_train)\n",
    "        mdl.fit(x_train, y_train, nb_epoch=20, batch_size=4000,validation_split=0.1)\n",
    "        y_test = mdl.predict(x_test)     \n",
    "        last.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('text_cnn')\n",
    "last.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lb.inverse_transform(sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장했다.\n"
     ]
    }
   ],
   "source": [
    "save_submission(testdf, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
