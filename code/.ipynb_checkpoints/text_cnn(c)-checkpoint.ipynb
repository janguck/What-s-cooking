{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ml_python/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from common_helper import *\n",
    "from text_cnn_helper import *\n",
    "from nltk_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"../input/train.json\"\n",
    "test_directory = \"../input/test.json\"\n",
    "traindf, testdf = data_load(train_directory,test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data_preprocessing(traindf)\n",
    "x_test, _ = data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [ x.split(\",\") for x in x_train]\n",
    "x_test = [ x.split(\",\") for x in x_test]\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(traindf.cuisine.values)\n",
    "y_train = lb.transform(traindf.cuisine.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test = pad_sentences(x_train,x_test)\n",
    "vocabulary, vocabulary_inv = build_vocab(x_train+x_test)\n",
    "x_train, x_test = build_input_data(x_train, x_test, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/160\n",
      "35796/35796 [==============================] - 6s 160us/step - loss: 2.9002 - acc: 0.1470 - val_loss: 2.8097 - val_acc: 0.1890\n",
      "Epoch 2/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 2.7372 - acc: 0.2086 - val_loss: 2.6743 - val_acc: 0.1890\n",
      "Epoch 3/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 2.6172 - acc: 0.2101 - val_loss: 2.5887 - val_acc: 0.1893\n",
      "Epoch 4/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 2.5469 - acc: 0.2264 - val_loss: 2.5479 - val_acc: 0.2318\n",
      "Epoch 5/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 2.5094 - acc: 0.2730 - val_loss: 2.5115 - val_acc: 0.3012\n",
      "Epoch 6/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 2.4700 - acc: 0.3032 - val_loss: 2.4695 - val_acc: 0.3092\n",
      "Epoch 7/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 2.4240 - acc: 0.3221 - val_loss: 2.4213 - val_acc: 0.3225\n",
      "Epoch 8/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 2.3709 - acc: 0.3468 - val_loss: 2.3637 - val_acc: 0.3524\n",
      "Epoch 9/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 2.3068 - acc: 0.3805 - val_loss: 2.2961 - val_acc: 0.3896\n",
      "Epoch 10/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 2.2337 - acc: 0.4150 - val_loss: 2.2192 - val_acc: 0.4279\n",
      "Epoch 11/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 2.1518 - acc: 0.4465 - val_loss: 2.1353 - val_acc: 0.4545\n",
      "Epoch 12/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 2.0667 - acc: 0.4719 - val_loss: 2.0477 - val_acc: 0.4723\n",
      "Epoch 13/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.9769 - acc: 0.4927 - val_loss: 1.9608 - val_acc: 0.4910\n",
      "Epoch 14/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 1.8904 - acc: 0.5097 - val_loss: 1.8775 - val_acc: 0.5048\n",
      "Epoch 15/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.8092 - acc: 0.5239 - val_loss: 1.7992 - val_acc: 0.5201\n",
      "Epoch 16/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.7327 - acc: 0.5385 - val_loss: 1.7273 - val_acc: 0.5322\n",
      "Epoch 17/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.6639 - acc: 0.5508 - val_loss: 1.6614 - val_acc: 0.5432\n",
      "Epoch 18/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.6008 - acc: 0.5636 - val_loss: 1.6012 - val_acc: 0.5546\n",
      "Epoch 19/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.5423 - acc: 0.5751 - val_loss: 1.5458 - val_acc: 0.5646\n",
      "Epoch 20/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.4874 - acc: 0.5870 - val_loss: 1.4955 - val_acc: 0.5804\n",
      "Epoch 21/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.4376 - acc: 0.5983 - val_loss: 1.4482 - val_acc: 0.5907\n",
      "Epoch 22/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.3909 - acc: 0.6098 - val_loss: 1.4042 - val_acc: 0.5988\n",
      "Epoch 23/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.3460 - acc: 0.6212 - val_loss: 1.3637 - val_acc: 0.6121\n",
      "Epoch 24/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.3072 - acc: 0.6309 - val_loss: 1.3255 - val_acc: 0.6187\n",
      "Epoch 25/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.2669 - acc: 0.6404 - val_loss: 1.2893 - val_acc: 0.6259\n",
      "Epoch 26/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.2304 - acc: 0.6502 - val_loss: 1.2558 - val_acc: 0.6370\n",
      "Epoch 27/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.1942 - acc: 0.6590 - val_loss: 1.2243 - val_acc: 0.6430\n",
      "Epoch 28/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.1620 - acc: 0.6687 - val_loss: 1.1948 - val_acc: 0.6508\n",
      "Epoch 29/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.1308 - acc: 0.6768 - val_loss: 1.1670 - val_acc: 0.6559\n",
      "Epoch 30/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 1.1011 - acc: 0.6834 - val_loss: 1.1413 - val_acc: 0.6634\n",
      "Epoch 31/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.0749 - acc: 0.6908 - val_loss: 1.1171 - val_acc: 0.6679\n",
      "Epoch 32/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 1.0494 - acc: 0.6970 - val_loss: 1.0948 - val_acc: 0.6747\n",
      "Epoch 33/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 1.0232 - acc: 0.7022 - val_loss: 1.0741 - val_acc: 0.6802\n",
      "Epoch 34/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 1.0010 - acc: 0.7097 - val_loss: 1.0544 - val_acc: 0.6865\n",
      "Epoch 35/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.9792 - acc: 0.7166 - val_loss: 1.0368 - val_acc: 0.6916\n",
      "Epoch 36/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.9584 - acc: 0.7205 - val_loss: 1.0200 - val_acc: 0.6981\n",
      "Epoch 37/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.9381 - acc: 0.7280 - val_loss: 1.0042 - val_acc: 0.7029\n",
      "Epoch 38/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.9178 - acc: 0.7321 - val_loss: 0.9895 - val_acc: 0.7064\n",
      "Epoch 39/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.9019 - acc: 0.7357 - val_loss: 0.9759 - val_acc: 0.7104\n",
      "Epoch 40/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.8837 - acc: 0.7424 - val_loss: 0.9631 - val_acc: 0.7144\n",
      "Epoch 41/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.8688 - acc: 0.7441 - val_loss: 0.9507 - val_acc: 0.7187\n",
      "Epoch 42/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.8527 - acc: 0.7509 - val_loss: 0.9394 - val_acc: 0.7225\n",
      "Epoch 43/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.8371 - acc: 0.7546 - val_loss: 0.9281 - val_acc: 0.7257\n",
      "Epoch 44/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.8228 - acc: 0.7591 - val_loss: 0.9181 - val_acc: 0.7272\n",
      "Epoch 45/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.8074 - acc: 0.7640 - val_loss: 0.9086 - val_acc: 0.7293\n",
      "Epoch 46/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.7930 - acc: 0.7695 - val_loss: 0.8986 - val_acc: 0.7305\n",
      "Epoch 47/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.7798 - acc: 0.7736 - val_loss: 0.8897 - val_acc: 0.7325\n",
      "Epoch 48/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.7671 - acc: 0.7761 - val_loss: 0.8812 - val_acc: 0.7366\n",
      "Epoch 49/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.7532 - acc: 0.7836 - val_loss: 0.8732 - val_acc: 0.7393\n",
      "Epoch 50/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.7435 - acc: 0.7841 - val_loss: 0.8654 - val_acc: 0.7403\n",
      "Epoch 51/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.7294 - acc: 0.7883 - val_loss: 0.8580 - val_acc: 0.7421\n",
      "Epoch 52/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.7184 - acc: 0.7936 - val_loss: 0.8507 - val_acc: 0.7441\n",
      "Epoch 53/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.7075 - acc: 0.7944 - val_loss: 0.8441 - val_acc: 0.7461\n",
      "Epoch 54/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.6954 - acc: 0.7987 - val_loss: 0.8379 - val_acc: 0.7476\n",
      "Epoch 55/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.6853 - acc: 0.8031 - val_loss: 0.8312 - val_acc: 0.7509\n",
      "Epoch 56/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.6736 - acc: 0.8070 - val_loss: 0.8250 - val_acc: 0.7541\n",
      "Epoch 57/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.6631 - acc: 0.8097 - val_loss: 0.8196 - val_acc: 0.7557\n",
      "Epoch 58/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.6534 - acc: 0.8122 - val_loss: 0.8144 - val_acc: 0.7572\n",
      "Epoch 59/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.6440 - acc: 0.8160 - val_loss: 0.8088 - val_acc: 0.7597\n",
      "Epoch 60/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.6339 - acc: 0.8194 - val_loss: 0.8039 - val_acc: 0.7609\n",
      "Epoch 61/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.6239 - acc: 0.8205 - val_loss: 0.7991 - val_acc: 0.7619\n",
      "Epoch 62/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.6153 - acc: 0.8232 - val_loss: 0.7945 - val_acc: 0.7619\n",
      "Epoch 63/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.6068 - acc: 0.8261 - val_loss: 0.7900 - val_acc: 0.7647\n",
      "Epoch 64/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5981 - acc: 0.8284 - val_loss: 0.7858 - val_acc: 0.7652\n",
      "Epoch 65/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5890 - acc: 0.8318 - val_loss: 0.7821 - val_acc: 0.7665\n",
      "Epoch 66/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5813 - acc: 0.8339 - val_loss: 0.7785 - val_acc: 0.7672\n",
      "Epoch 67/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5731 - acc: 0.8377 - val_loss: 0.7745 - val_acc: 0.7692\n",
      "Epoch 68/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5639 - acc: 0.8379 - val_loss: 0.7716 - val_acc: 0.7680\n",
      "Epoch 69/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5570 - acc: 0.8419 - val_loss: 0.7679 - val_acc: 0.7695\n",
      "Epoch 70/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5500 - acc: 0.8427 - val_loss: 0.7654 - val_acc: 0.7697\n",
      "Epoch 71/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5423 - acc: 0.8438 - val_loss: 0.7624 - val_acc: 0.7710\n",
      "Epoch 72/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5363 - acc: 0.8479 - val_loss: 0.7593 - val_acc: 0.7715\n",
      "Epoch 73/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5288 - acc: 0.8501 - val_loss: 0.7569 - val_acc: 0.7740\n",
      "Epoch 74/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5213 - acc: 0.8521 - val_loss: 0.7543 - val_acc: 0.7745\n",
      "Epoch 75/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5157 - acc: 0.8533 - val_loss: 0.7522 - val_acc: 0.7743\n",
      "Epoch 76/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.5089 - acc: 0.8557 - val_loss: 0.7500 - val_acc: 0.7750\n",
      "Epoch 77/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.5011 - acc: 0.8584 - val_loss: 0.7481 - val_acc: 0.7755\n",
      "Epoch 78/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4958 - acc: 0.8593 - val_loss: 0.7461 - val_acc: 0.7768\n",
      "Epoch 79/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4900 - acc: 0.8610 - val_loss: 0.7439 - val_acc: 0.7775\n",
      "Epoch 80/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4827 - acc: 0.8626 - val_loss: 0.7425 - val_acc: 0.7765\n",
      "Epoch 81/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4780 - acc: 0.8635 - val_loss: 0.7406 - val_acc: 0.7790\n",
      "Epoch 82/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4712 - acc: 0.8667 - val_loss: 0.7394 - val_acc: 0.7775\n",
      "Epoch 83/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4652 - acc: 0.8686 - val_loss: 0.7379 - val_acc: 0.7780\n",
      "Epoch 84/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4611 - acc: 0.8680 - val_loss: 0.7369 - val_acc: 0.7775\n",
      "Epoch 85/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4558 - acc: 0.8696 - val_loss: 0.7355 - val_acc: 0.7800\n",
      "Epoch 86/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4506 - acc: 0.8719 - val_loss: 0.7341 - val_acc: 0.7800\n",
      "Epoch 87/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4452 - acc: 0.8733 - val_loss: 0.7330 - val_acc: 0.7818\n",
      "Epoch 88/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4388 - acc: 0.8752 - val_loss: 0.7326 - val_acc: 0.7810\n",
      "Epoch 89/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4330 - acc: 0.8764 - val_loss: 0.7313 - val_acc: 0.7818\n",
      "Epoch 90/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4308 - acc: 0.8774 - val_loss: 0.7307 - val_acc: 0.7823\n",
      "Epoch 91/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4253 - acc: 0.8800 - val_loss: 0.7298 - val_acc: 0.7823\n",
      "Epoch 92/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 0.4198 - acc: 0.8811 - val_loss: 0.7291 - val_acc: 0.7833\n",
      "Epoch 93/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4154 - acc: 0.8817 - val_loss: 0.7286 - val_acc: 0.7828\n",
      "Epoch 94/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4117 - acc: 0.8835 - val_loss: 0.7286 - val_acc: 0.7826\n",
      "Epoch 95/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.4046 - acc: 0.8838 - val_loss: 0.7278 - val_acc: 0.7833\n",
      "Epoch 96/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.4020 - acc: 0.8862 - val_loss: 0.7276 - val_acc: 0.7833\n",
      "Epoch 97/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3983 - acc: 0.8864 - val_loss: 0.7270 - val_acc: 0.7833\n",
      "Epoch 98/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3915 - acc: 0.8893 - val_loss: 0.7271 - val_acc: 0.7836\n",
      "Epoch 99/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3882 - acc: 0.8895 - val_loss: 0.7265 - val_acc: 0.7846\n",
      "Epoch 100/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.3815 - acc: 0.8917 - val_loss: 0.7264 - val_acc: 0.7843\n",
      "Epoch 101/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3795 - acc: 0.8933 - val_loss: 0.7265 - val_acc: 0.7843\n",
      "Epoch 102/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 0.3748 - acc: 0.8942 - val_loss: 0.7268 - val_acc: 0.7861\n",
      "Epoch 103/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3731 - acc: 0.8942 - val_loss: 0.7271 - val_acc: 0.7856\n",
      "Epoch 104/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3679 - acc: 0.8952 - val_loss: 0.7263 - val_acc: 0.7853\n",
      "Epoch 105/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.3637 - acc: 0.8978 - val_loss: 0.7267 - val_acc: 0.7868\n",
      "Epoch 106/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.3607 - acc: 0.8983 - val_loss: 0.7270 - val_acc: 0.7873\n",
      "Epoch 107/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3566 - acc: 0.8996 - val_loss: 0.7273 - val_acc: 0.7878\n",
      "Epoch 108/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3530 - acc: 0.8999 - val_loss: 0.7279 - val_acc: 0.7873\n",
      "Epoch 109/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3475 - acc: 0.9007 - val_loss: 0.7279 - val_acc: 0.7881\n",
      "Epoch 110/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3461 - acc: 0.9027 - val_loss: 0.7282 - val_acc: 0.7881\n",
      "Epoch 111/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3412 - acc: 0.9036 - val_loss: 0.7285 - val_acc: 0.7876\n",
      "Epoch 112/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.3386 - acc: 0.9040 - val_loss: 0.7290 - val_acc: 0.7883\n",
      "Epoch 113/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 0.3339 - acc: 0.9060 - val_loss: 0.7303 - val_acc: 0.7883\n",
      "Epoch 114/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3313 - acc: 0.9061 - val_loss: 0.7304 - val_acc: 0.7893\n",
      "Epoch 115/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.3271 - acc: 0.9073 - val_loss: 0.7312 - val_acc: 0.7886\n",
      "Epoch 116/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.3251 - acc: 0.9087 - val_loss: 0.7322 - val_acc: 0.7886\n",
      "Epoch 117/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3219 - acc: 0.9095 - val_loss: 0.7325 - val_acc: 0.7883\n",
      "Epoch 118/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3159 - acc: 0.9119 - val_loss: 0.7331 - val_acc: 0.7881\n",
      "Epoch 119/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3145 - acc: 0.9115 - val_loss: 0.7337 - val_acc: 0.7878\n",
      "Epoch 120/160\n",
      "35796/35796 [==============================] - 5s 153us/step - loss: 0.3122 - acc: 0.9123 - val_loss: 0.7346 - val_acc: 0.7878\n",
      "Epoch 121/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3069 - acc: 0.9125 - val_loss: 0.7351 - val_acc: 0.7888\n",
      "Epoch 122/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.3069 - acc: 0.9133 - val_loss: 0.7356 - val_acc: 0.7891\n",
      "Epoch 123/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.3019 - acc: 0.9159 - val_loss: 0.7372 - val_acc: 0.7873\n",
      "Epoch 124/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2998 - acc: 0.9175 - val_loss: 0.7376 - val_acc: 0.7901\n",
      "Epoch 125/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2967 - acc: 0.9161 - val_loss: 0.7388 - val_acc: 0.7891\n",
      "Epoch 126/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2927 - acc: 0.9189 - val_loss: 0.7398 - val_acc: 0.7891\n",
      "Epoch 127/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.2907 - acc: 0.9196 - val_loss: 0.7404 - val_acc: 0.7891\n",
      "Epoch 128/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2873 - acc: 0.9200 - val_loss: 0.7416 - val_acc: 0.7898\n",
      "Epoch 129/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2843 - acc: 0.9217 - val_loss: 0.7425 - val_acc: 0.7906\n",
      "Epoch 130/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2800 - acc: 0.9224 - val_loss: 0.7439 - val_acc: 0.7908\n",
      "Epoch 131/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2796 - acc: 0.9219 - val_loss: 0.7449 - val_acc: 0.7908\n",
      "Epoch 132/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2768 - acc: 0.9238 - val_loss: 0.7459 - val_acc: 0.7908\n",
      "Epoch 133/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2731 - acc: 0.9233 - val_loss: 0.7470 - val_acc: 0.7906\n",
      "Epoch 134/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.2696 - acc: 0.9254 - val_loss: 0.7477 - val_acc: 0.7906\n",
      "Epoch 135/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2689 - acc: 0.9249 - val_loss: 0.7487 - val_acc: 0.7891\n",
      "Epoch 136/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2649 - acc: 0.9261 - val_loss: 0.7502 - val_acc: 0.7901\n",
      "Epoch 137/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2637 - acc: 0.9271 - val_loss: 0.7516 - val_acc: 0.7896\n",
      "Epoch 138/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2605 - acc: 0.9284 - val_loss: 0.7522 - val_acc: 0.7903\n",
      "Epoch 139/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2576 - acc: 0.9288 - val_loss: 0.7536 - val_acc: 0.7898\n",
      "Epoch 140/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2544 - acc: 0.9300 - val_loss: 0.7541 - val_acc: 0.7898\n",
      "Epoch 141/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2523 - acc: 0.9305 - val_loss: 0.7564 - val_acc: 0.7886\n",
      "Epoch 142/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2482 - acc: 0.9321 - val_loss: 0.7571 - val_acc: 0.7886\n",
      "Epoch 143/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2459 - acc: 0.9328 - val_loss: 0.7586 - val_acc: 0.7888\n",
      "Epoch 144/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2459 - acc: 0.9333 - val_loss: 0.7606 - val_acc: 0.7876\n",
      "Epoch 145/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2428 - acc: 0.9341 - val_loss: 0.7615 - val_acc: 0.7891\n",
      "Epoch 146/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2412 - acc: 0.9343 - val_loss: 0.7626 - val_acc: 0.7888\n",
      "Epoch 147/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2370 - acc: 0.9358 - val_loss: 0.7646 - val_acc: 0.7878\n",
      "Epoch 148/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2370 - acc: 0.9342 - val_loss: 0.7659 - val_acc: 0.7868\n",
      "Epoch 149/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.2317 - acc: 0.9377 - val_loss: 0.7675 - val_acc: 0.7878\n",
      "Epoch 150/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2300 - acc: 0.9375 - val_loss: 0.7684 - val_acc: 0.7876\n",
      "Epoch 151/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2291 - acc: 0.9378 - val_loss: 0.7702 - val_acc: 0.7878\n",
      "Epoch 152/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.2264 - acc: 0.9392 - val_loss: 0.7715 - val_acc: 0.7883\n",
      "Epoch 153/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2256 - acc: 0.9385 - val_loss: 0.7731 - val_acc: 0.7878\n",
      "Epoch 154/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2227 - acc: 0.9406 - val_loss: 0.7745 - val_acc: 0.7876\n",
      "Epoch 155/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2204 - acc: 0.9409 - val_loss: 0.7755 - val_acc: 0.7873\n",
      "Epoch 156/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2190 - acc: 0.9406 - val_loss: 0.7772 - val_acc: 0.7871\n",
      "Epoch 157/160\n",
      "35796/35796 [==============================] - 5s 152us/step - loss: 0.2154 - acc: 0.9434 - val_loss: 0.7789 - val_acc: 0.7868\n",
      "Epoch 158/160\n",
      "35796/35796 [==============================] - 5s 150us/step - loss: 0.2145 - acc: 0.9428 - val_loss: 0.7797 - val_acc: 0.7868\n",
      "Epoch 159/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2120 - acc: 0.9444 - val_loss: 0.7819 - val_acc: 0.7871\n",
      "Epoch 160/160\n",
      "35796/35796 [==============================] - 5s 151us/step - loss: 0.2115 - acc: 0.9428 - val_loss: 0.7837 - val_acc: 0.7861\n",
      "저장했다.\n"
     ]
    }
   ],
   "source": [
    "epochs = 160\n",
    "batch_size = 3000\n",
    "\n",
    "with K.tf.device('/gpu:0'):\n",
    "    model = model_load(x_train, vocabulary_inv)\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,validation_split=0.1)\n",
    "    predictions = model.predict(x_test)\n",
    "    save_submission(testdf, lb.inverse_transform(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.dump(\"text_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0395333e-03, 5.9927130e-01, 2.4807025e-04, ..., 4.6130237e-03,\n",
       "        9.5377595e-04, 6.7234965e-04],\n",
       "       [2.1853803e-04, 7.1403529e-03, 5.3535745e-04, ..., 1.8175048e-06,\n",
       "        1.2740270e-06, 1.7054748e-05],\n",
       "       [4.4508781e-03, 4.7409569e-04, 4.9937160e-05, ..., 2.5165660e-02,\n",
       "        7.4264863e-05, 2.9697191e-04],\n",
       "       ...,\n",
       "       [1.1111313e-04, 6.7154433e-06, 2.0376302e-03, ..., 1.6695104e-03,\n",
       "        1.4754658e-06, 5.2112919e-06],\n",
       "       [9.8804822e-03, 1.1084268e-04, 5.2335884e-02, ..., 1.4760699e-03,\n",
       "        2.7278244e-05, 9.5797195e-06],\n",
       "       [1.5979854e-06, 7.7505303e-12, 3.1774017e-09, ..., 4.5202542e-06,\n",
       "        2.7560447e-09, 3.8442513e-10]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('text_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(users, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
