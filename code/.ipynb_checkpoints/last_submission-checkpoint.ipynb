{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ml_python/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from common_helper import *\n",
    "from nltk_helper import *\n",
    "from keras_helper import *\n",
    "from vectorizer_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dr = \"../input/train.json\"\n",
    "test_dr = \"../input/test.json\"\n",
    "traindf, testdf = data_load(train_dr, test_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_train_word, y_train = word_data_preprocessing(traindf)\n",
    "x_test_word, _ = word_data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_train_token, y_train = token_data_preprocessing(traindf)\n",
    "x_test_token, _ = token_data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_train_char, y_train = char_data_preprocessing(traindf)\n",
    "x_test_char, _ = char_data_preprocessing(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_word, x_test_word, word_tfidf = tfidf_vectorizer(_x_train_word, x_test_word, \",\")\n",
    "x_train_token, x_test_token, token_tfidf = tfidf_vectorizer(_x_train_token, x_test_token, \",\")\n",
    "x_train_char, x_test_char, char_cntvec = char_vectorizer(_x_train_char, x_test_char, \"char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = ['spanish','irish','russian','chinese','brazilian','vietnamese','greek','british','filipino', 'korean']\n",
    "column = ['korean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_word, x_test_word = jump_value(traindf, column, word_tfidf, _x_train_word, x_train_word, x_test_word, 1.5, 300000, 100000)\n",
    "# x_train_token, x_test_token = jump_value(traindf, column, token_tfidf, _x_train_token, x_train_token, x_test_token, 1.5, 300000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(traindf.cuisine.values)\n",
    "y_train = lb.transform(traindf.cuisine.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_word, x_train_token), axis=1)\n",
    "x_test = np.concatenate((x_test_word, x_test_token), axis=1)\n",
    "x_train = np.concatenate((x_train, x_train_char), axis=1)\n",
    "x_test = np.concatenate((x_test, x_test_char), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/strawberry/code/keras_helper.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(540, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_shape=(9712,))`\n",
      "  model.add(Dense(540, init='glorot_uniform', activation='relu', input_shape=(x_train.shape[1],)))\n",
      "/root/strawberry/code/keras_helper.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(180, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(180, init='glorot_uniform', activation='relu'))\n",
      "/root/anaconda3/envs/ml_python/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/17\n",
      "35796/35796 [==============================] - 4s 124us/step - loss: 2.7307 - acc: 0.2044 - val_loss: 2.4217 - val_acc: 0.3115\n",
      "Epoch 2/17\n",
      "35796/35796 [==============================] - 3s 91us/step - loss: 2.3725 - acc: 0.3451 - val_loss: 2.0717 - val_acc: 0.4522\n",
      "Epoch 3/17\n",
      "35796/35796 [==============================] - 3s 93us/step - loss: 2.0758 - acc: 0.4405 - val_loss: 1.8238 - val_acc: 0.4947\n",
      "Epoch 4/17\n",
      "35796/35796 [==============================] - 3s 95us/step - loss: 1.8433 - acc: 0.4956 - val_loss: 1.6071 - val_acc: 0.5473\n",
      "Epoch 5/17\n",
      "35796/35796 [==============================] - 3s 95us/step - loss: 1.6324 - acc: 0.5438 - val_loss: 1.4000 - val_acc: 0.6031\n",
      "Epoch 6/17\n",
      "35796/35796 [==============================] - 3s 95us/step - loss: 1.4583 - acc: 0.5888 - val_loss: 1.2361 - val_acc: 0.6383\n",
      "Epoch 7/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 1.3121 - acc: 0.6266 - val_loss: 1.1083 - val_acc: 0.6702\n",
      "Epoch 8/17\n",
      "35796/35796 [==============================] - 3s 93us/step - loss: 1.1875 - acc: 0.6569 - val_loss: 1.0112 - val_acc: 0.6978\n",
      "Epoch 9/17\n",
      "35796/35796 [==============================] - 3s 95us/step - loss: 1.0888 - acc: 0.6854 - val_loss: 0.9379 - val_acc: 0.7200\n",
      "Epoch 10/17\n",
      "35796/35796 [==============================] - 3s 92us/step - loss: 1.0061 - acc: 0.7084 - val_loss: 0.8822 - val_acc: 0.7338\n",
      "Epoch 11/17\n",
      "35796/35796 [==============================] - 3s 91us/step - loss: 0.9338 - acc: 0.7289 - val_loss: 0.8335 - val_acc: 0.7511\n",
      "Epoch 12/17\n",
      "35796/35796 [==============================] - 3s 88us/step - loss: 0.8745 - acc: 0.7492 - val_loss: 0.7905 - val_acc: 0.7675\n",
      "Epoch 13/17\n",
      "35796/35796 [==============================] - 3s 95us/step - loss: 0.8235 - acc: 0.7613 - val_loss: 0.7594 - val_acc: 0.7773\n",
      "Epoch 14/17\n",
      "35796/35796 [==============================] - 3s 92us/step - loss: 0.7732 - acc: 0.7760 - val_loss: 0.7356 - val_acc: 0.7848\n",
      "Epoch 15/17\n",
      "35796/35796 [==============================] - 3s 91us/step - loss: 0.7430 - acc: 0.7841 - val_loss: 0.7188 - val_acc: 0.7906\n",
      "Epoch 16/17\n",
      "35796/35796 [==============================] - 3s 89us/step - loss: 0.7004 - acc: 0.7971 - val_loss: 0.7077 - val_acc: 0.7924\n",
      "Epoch 17/17\n",
      "35796/35796 [==============================] - 3s 90us/step - loss: 0.6710 - acc: 0.8060 - val_loss: 0.6870 - val_acc: 0.8009\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/17\n",
      "35796/35796 [==============================] - 4s 100us/step - loss: 2.7627 - acc: 0.2071 - val_loss: 2.4761 - val_acc: 0.3112\n",
      "Epoch 2/17\n",
      "35796/35796 [==============================] - 3s 90us/step - loss: 2.4159 - acc: 0.3239 - val_loss: 2.1288 - val_acc: 0.4268\n",
      "Epoch 3/17\n",
      "35796/35796 [==============================] - 3s 90us/step - loss: 2.1213 - acc: 0.4210 - val_loss: 1.8485 - val_acc: 0.4867\n",
      "Epoch 4/17\n",
      "35796/35796 [==============================] - 3s 88us/step - loss: 1.8751 - acc: 0.4845 - val_loss: 1.6255 - val_acc: 0.5455\n",
      "Epoch 5/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 1.6675 - acc: 0.5380 - val_loss: 1.4313 - val_acc: 0.5882\n",
      "Epoch 6/17\n",
      "35796/35796 [==============================] - 3s 96us/step - loss: 1.4904 - acc: 0.5793 - val_loss: 1.2677 - val_acc: 0.6317\n",
      "Epoch 7/17\n",
      "35796/35796 [==============================] - 3s 92us/step - loss: 1.3400 - acc: 0.6150 - val_loss: 1.1467 - val_acc: 0.6589\n",
      "Epoch 8/17\n",
      "35796/35796 [==============================] - 3s 92us/step - loss: 1.2135 - acc: 0.6469 - val_loss: 1.0449 - val_acc: 0.6863\n",
      "Epoch 9/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 1.1224 - acc: 0.6720 - val_loss: 0.9620 - val_acc: 0.7114\n",
      "Epoch 10/17\n",
      "35796/35796 [==============================] - 3s 89us/step - loss: 1.0326 - acc: 0.6987 - val_loss: 0.9059 - val_acc: 0.7288\n",
      "Epoch 11/17\n",
      "35796/35796 [==============================] - 3s 86us/step - loss: 0.9631 - acc: 0.7191 - val_loss: 0.8506 - val_acc: 0.7471\n",
      "Epoch 12/17\n",
      "35796/35796 [==============================] - 3s 89us/step - loss: 0.9055 - acc: 0.7377 - val_loss: 0.8116 - val_acc: 0.7572\n",
      "Epoch 13/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.8518 - acc: 0.7546 - val_loss: 0.7844 - val_acc: 0.7672\n",
      "Epoch 14/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 0.8031 - acc: 0.7687 - val_loss: 0.7567 - val_acc: 0.7743\n",
      "Epoch 15/17\n",
      "35796/35796 [==============================] - 3s 88us/step - loss: 0.7641 - acc: 0.7769 - val_loss: 0.7306 - val_acc: 0.7836\n",
      "Epoch 16/17\n",
      "35796/35796 [==============================] - 3s 86us/step - loss: 0.7225 - acc: 0.7927 - val_loss: 0.7132 - val_acc: 0.7924\n",
      "Epoch 17/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.6943 - acc: 0.7994 - val_loss: 0.7049 - val_acc: 0.7916\n",
      "Train on 35796 samples, validate on 3978 samples\n",
      "Epoch 1/17\n",
      "35796/35796 [==============================] - 3s 93us/step - loss: 2.7945 - acc: 0.1869 - val_loss: 2.4517 - val_acc: 0.3017\n",
      "Epoch 2/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 2.4184 - acc: 0.3290 - val_loss: 2.1167 - val_acc: 0.4289\n",
      "Epoch 3/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 2.1220 - acc: 0.4230 - val_loss: 1.8531 - val_acc: 0.4874\n",
      "Epoch 4/17\n",
      "35796/35796 [==============================] - 3s 92us/step - loss: 1.8769 - acc: 0.4855 - val_loss: 1.6396 - val_acc: 0.5452\n",
      "Epoch 5/17\n",
      "35796/35796 [==============================] - 3s 86us/step - loss: 1.6715 - acc: 0.5347 - val_loss: 1.4448 - val_acc: 0.5902\n",
      "Epoch 6/17\n",
      "35796/35796 [==============================] - 3s 89us/step - loss: 1.4901 - acc: 0.5808 - val_loss: 1.2806 - val_acc: 0.6305\n",
      "Epoch 7/17\n",
      "35796/35796 [==============================] - 3s 97us/step - loss: 1.3403 - acc: 0.6172 - val_loss: 1.1486 - val_acc: 0.6624\n",
      "Epoch 8/17\n",
      "35796/35796 [==============================] - 3s 97us/step - loss: 1.2230 - acc: 0.6463 - val_loss: 1.0639 - val_acc: 0.6840\n",
      "Epoch 9/17\n",
      "35796/35796 [==============================] - 3s 97us/step - loss: 1.1192 - acc: 0.6738 - val_loss: 0.9758 - val_acc: 0.7084\n",
      "Epoch 10/17\n",
      "35796/35796 [==============================] - 3s 88us/step - loss: 1.0319 - acc: 0.6997 - val_loss: 0.9019 - val_acc: 0.7325\n",
      "Epoch 11/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.9616 - acc: 0.7210 - val_loss: 0.8580 - val_acc: 0.7396\n",
      "Epoch 12/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.8996 - acc: 0.7372 - val_loss: 0.8121 - val_acc: 0.7609\n",
      "Epoch 13/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.8504 - acc: 0.7527 - val_loss: 0.7805 - val_acc: 0.7692\n",
      "Epoch 14/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.8033 - acc: 0.7685 - val_loss: 0.7579 - val_acc: 0.7735\n",
      "Epoch 15/17\n",
      "35796/35796 [==============================] - 3s 87us/step - loss: 0.7640 - acc: 0.7796 - val_loss: 0.7342 - val_acc: 0.7841\n",
      "Epoch 16/17\n",
      "35796/35796 [==============================] - 3s 88us/step - loss: 0.7253 - acc: 0.7897 - val_loss: 0.7178 - val_acc: 0.7901\n",
      "Epoch 17/17\n",
      "35796/35796 [==============================] - 3s 94us/step - loss: 0.6925 - acc: 0.7990 - val_loss: 0.7140 - val_acc: 0.7866\n"
     ]
    }
   ],
   "source": [
    "ensemble_train = []\n",
    "ensemble_test = []\n",
    "\n",
    "for i in range(3):\n",
    "    with K.tf.device('/gpu:0'):\n",
    "        mdl = load_model(x_train)\n",
    "        mdl.fit(x_train, y_train, nb_epoch=17, batch_size=4000,validation_split=0.1)\n",
    "        ensemble_train.append(mdl.predict(x_train))\n",
    "        ensemble_test.append(mdl.predict(x_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장했다.\n"
     ]
    }
   ],
   "source": [
    "result = lb.inverse_transform(sum(ensemble_test))\n",
    "save_submission(testdf, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lb.inverse_transform(sum(ensemble_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['predictions'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = Counter(traindf['cuisine'].tolist())\n",
    "error = Counter(traindf['cuisine'][traindf['predictions'] != traindf['cuisine']].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['cuisine'][traindf['predictions'] != traindf['cuisine']].tolist().count('korean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "british 의 오답개수는 443\n",
      "british 의 오답률은  0.5509950248756219\n",
      "\n",
      "\n",
      "filipino 의 오답개수는 294\n",
      "filipino 의 오답률은  0.3894039735099338\n",
      "\n",
      "\n",
      "jamaican 의 오답개수는 107\n",
      "jamaican 의 오답률은  0.20342205323193915\n",
      "\n",
      "\n",
      "irish 의 오답개수는 229\n",
      "irish 의 오답률은  0.34332833583208394\n",
      "\n",
      "\n",
      "russian 의 오답개수는 233\n",
      "russian 의 오답률은  0.47648261758691207\n",
      "\n",
      "\n",
      "moroccan 의 오답개수는 263\n",
      "moroccan 의 오답률은  0.32034104750304504\n",
      "\n",
      "\n",
      "vietnamese 의 오답개수는 260\n",
      "vietnamese 의 오답률은  0.3151515151515151\n",
      "\n",
      "\n",
      "spanish 의 오답개수는 269\n",
      "spanish 의 오답률은  0.27199191102123355\n",
      "\n",
      "\n",
      "japanese 의 오답개수는 408\n",
      "japanese 의 오답률은  0.286718200983837\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t,e in zip(total,error):\n",
    "    if error[e]/total[t] > 0.2:\n",
    "        print(str(t),\"의 오답개수는\",str(error[e]))\n",
    "        print(str(t),\"의 오답률은 \",str(error[e]/total[t]))             \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
